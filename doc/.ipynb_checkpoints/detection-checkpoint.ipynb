{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import collections\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean file function\n",
    "def clean(words):\n",
    "    out = []\n",
    "    for c in words:\n",
    "        c = c.lower()\n",
    "        if c in set('abcdefghijklmnopqrstuvwxyz '):\n",
    "            out.append(c)\n",
    "    return ''.join(out)\n",
    "\n",
    "# transfrom characters to numbers\n",
    "def char_to_index(char):\n",
    "    return ord(char)-ord('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Combine ground truth and orc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set file path\n",
    "input_path = '../data/'\n",
    "if not os.path.exists('../output/Detection/'):\n",
    "    os.mkdir('../output/Detection/')\n",
    "output_path = '../output/Detection/'\n",
    "\n",
    "#create files of ground truth\n",
    "with open(os.path.join(output_path, 'truth_combined.txt'), 'wb') as output1:\n",
    "    filelist = sorted(glob.glob(os.path.join(input_path, 'ground_truth/'+'*.txt')))\n",
    "    for file in filelist:\n",
    "        with open(file, 'rb') as input1:\n",
    "            output1.write(input1.read())\n",
    "\n",
    "#create files of orc\n",
    "with open(os.path.join(output_path, 'orc_combined.txt'), 'wb') as output2:\n",
    "    filelist = sorted(glob.glob(os.path.join(input_path, 'tesseract/'+'*.txt')))\n",
    "    for file in filelist:\n",
    "        with open(file, 'rb') as input2:\n",
    "            output2.write(input2.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert groud true files to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cleaned truth files for dictionary, only keep characters and space\n",
    "with open(os.path.join(output_path, 'truth_cleaned.txt'), 'w') as output3:\n",
    "    with open(os.path.join(output_path, 'truth_combined.txt'), 'r') as input3:\n",
    "        for line in input3:\n",
    "            out=clean(line)\n",
    "            output3.write(out+' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bags of words by length\n",
    "words_by_len = {}\n",
    "with open(os.path.join(output_path, 'truth_cleaned.txt'), 'r') as input0:\n",
    "    for line in input0:\n",
    "        line = line.strip().split()\n",
    "        if line:\n",
    "            for word in line:\n",
    "                if len(word) > 1:\n",
    "                    words_by_len.setdefault(len(word), set()).add(word)\n",
    "\n",
    "# create dictionary by length of words and bigram positions\n",
    "dic_by_len = collections.defaultdict(dict)\n",
    "for length in sorted(words_by_len.keys()):\n",
    "    for i, j in itertools.combinations(range(length), 2):\n",
    "        matrix = [[0]*26 for _ in range(26)]\n",
    "        for word in words_by_len[length]:\n",
    "            matrix[char_to_index(word[i])][char_to_index(word[j])] = 1\n",
    "            dic_by_len[length][(i,j)] = matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Detect error based on the dictionary we create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rules**: (0-error;1-good)  \n",
    "- If the word contains non-alphabetical characters, set it 0\n",
    "- If the word contains only one characters, set it 1 if 'a' and 'i' and 0 otherwise\n",
    "- Then set 1 or 0 in other cases according to the dictionary we create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(filename):\n",
    "    Detection_list=[]\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            for word in line.strip().split():\n",
    "                word = word.lower()\n",
    "                tmp = [c for c in word if c in set('abcdefghijklmnopqrstuvwxyz')]\n",
    "                if len(tmp) != len(word):\n",
    "                    # contain non-alphabetical characters\n",
    "                    Detection_list.append(0)\n",
    "                elif len(word)==1:\n",
    "                    if word == 'a' or word == 'i':\n",
    "                        # set it 1 if 'a' and 'i'\n",
    "                        Detection_list.append(1)\n",
    "                    else:\n",
    "                        # set it 0 otherwise\n",
    "                        Detection_list.append(0)\n",
    "                else:\n",
    "                    # according to the dictionary\n",
    "                    list1 = []\n",
    "                    for i, j in itertools.combinations(range(len(word)),2):\n",
    "                        key = (i, j)\n",
    "                        matrix=dic_by_len[len(word)][key]\n",
    "                        if matrix[char_to_index(word[i])][char_to_index(word[j])] == 1:\n",
    "                            list1.append(1)\n",
    "                        else:\n",
    "                            list1.append(0)\n",
    "                    if any(item == 0 for item in list1):\n",
    "                        Detection_list.append(0)\n",
    "                    else:\n",
    "                        Detection_list.append(1)\n",
    "    return Detection_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect error for the whole orc texts\n",
    "err = detect('../output/Detection/orc_combined.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Calculate the error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34465132160359924"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sum(err)/len(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Prepare for correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create truth file and orc file for correction\n",
    "def clean2(line):\n",
    "    line = line.lower()\n",
    "    line = line.strip().split()\n",
    "    res = []\n",
    "    for word in line:\n",
    "        if len(word) != len([c for c in word if c in set('abcdefghijklmnopqrstuvwxyz0123456789')]):\n",
    "            continue\n",
    "        else:\n",
    "            tmp = ''\n",
    "            for c in word:\n",
    "                if c in set('abcdefghijklmnopqrstuvwxyz'):\n",
    "                    tmp += c\n",
    "                else:\n",
    "                    tmp += list('abcdefghijklmnopqrstuvwxyz')[random.randint(0,25)]\n",
    "            res.append(tmp)\n",
    "    return ' '.join(res)\n",
    "\n",
    "if not os.path.exists('../output/Correction/'):\n",
    "    os.mkdir('../output/Correction/')\n",
    "\n",
    "truth_file = open(os.path.join(output_path, 'truth_combined.txt'),'r')\n",
    "orc_file = open(os.path.join(output_path, 'orc_combined.txt'),'r')\n",
    "with open('../output/Correction/truth_corrected.txt', 'w') as out_truth_file:\n",
    "    with open('../output/Correction/orc_corrected.txt', 'w') as out_orc_file:\n",
    "        for line1,line2 in zip(truth_file, orc_file):\n",
    "            line1 = clean2(line1)\n",
    "            line2 = clean2(line2)\n",
    "            if len(line1.strip().split()) == len(line2.strip().split()):\n",
    "                out_truth_file.write(line1+' ')\n",
    "                out_orc_file.write(line2+' ')\n",
    "truth_file.close()\n",
    "orc_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect error and output the matching\n",
    "err_num = detect('../output/Correction/orc_corrected.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1, list2 = [], []\n",
    "with open('../output/Correction/truth_corrected.txt') as file1:\n",
    "    for line in file1:\n",
    "        list1 += line.strip().split()\n",
    "\n",
    "with open('../output/Correction/orc_corrected.txt') as file2:\n",
    "    for line in file2:\n",
    "        list2 += (line.strip().split())\n",
    "\n",
    "def prev(num):\n",
    "    res = []\n",
    "    for i in range(len(list2)):\n",
    "        if i - num < 0:\n",
    "            res.append('*')\n",
    "        else:\n",
    "            res.append(list2[i-num])\n",
    "    return res\n",
    "def follow(num):\n",
    "    res = []\n",
    "    for i in range(len(list2)):\n",
    "        if i+num >= len(list2):\n",
    "            res.append('*')\n",
    "        else:\n",
    "            res.append(list2[i+num])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev1, prev2, prev3, prev4 = prev(1),prev(2),prev(3),prev(4)\n",
    "next1,next2,next3,next4 = follow(1),follow(2),follow(3),follow(4)\n",
    "\n",
    "matching2 = pd.DataFrame({'prev2':prev2,\n",
    "                          'prev1':prev1,\n",
    "                          'WORD_ORC':list2,\n",
    "                          'next1':next1,\n",
    "                          'next2':next2,\n",
    "                          'WORD_TRUE':list1,\n",
    "                          'SAME':[bool(x) for x in err_num]})\n",
    "matching4 = pd.DataFrame({'prev4':prev4,\n",
    "                          'prev3':prev3,\n",
    "                          'prev2':prev2,\n",
    "                          'prev1':prev1,\n",
    "                          'WORD_ORC':list2,\n",
    "                          'next1':next1,\n",
    "                          'next2':next2,\n",
    "                          'next3':next3,\n",
    "                          'next4':next4,\n",
    "                          'WORD_TRUR':list1,\n",
    "                          'SAME':[bool(x) for x in err_num]})\n",
    "\n",
    "matching2.to_csv('../output/Correction/matching2.csv')\n",
    "matching4.to_csv('../output/Correction/matching4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
