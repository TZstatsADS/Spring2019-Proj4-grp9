{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from Corrector import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory of 'Spring2019-Proj4-grp9'\n",
    "pwd = os.path.dirname(os.getcwd())\n",
    "# set the working directory of processed data\n",
    "Correction_wd = os.path.join(pwd, \"output\", \"Correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(Correction_wd, \"dataset.pkl\")):\n",
    "    dataset = pd.read_pickle(os.path.join(Correction_wd, \"dataset.pkl\"))\n",
    "else:\n",
    "    tic = time.clock()\n",
    "    # This is a Corrector object we defined for storing/processing data\n",
    "    corrector = Corrector()\n",
    "    # All the error and true words\n",
    "    We = list(corrector.error_text['WORD_OCR'])\n",
    "    Truth = list(corrector.error_text['WORD_TRUE'])\n",
    "    \n",
    "    # Initialize the dataset\n",
    "    dataset = pd.DataFrame()\n",
    "    \n",
    "    # Compute those scores\n",
    "    for i in range(len(We)):\n",
    "        data_piece = pd.DataFrame()\n",
    "        for Threshold in range(10):\n",
    "            candidates = corrector.candidate_search(We[i], Threshold)\n",
    "            if len(candidates) >= 10:\n",
    "                break\n",
    "\n",
    "        dist_score = distance_score(candidates, We[i], Threshold)\n",
    "        simi_score = similarity_score(candidates, We[i])\n",
    "        popu_score = popularity_score(candidates)\n",
    "        exis_score = existance_score(candidates, corrector.lexicon)\n",
    "        exat_score = exact_popularity_score(candidates, We[i], three_gram(corrector.error_text.iloc[i]),\n",
    "                                            corrector.dictionary_exact)\n",
    "        rela_score = relaxed_popularity_score(candidates, We[i], three_gram(corrector.error_text.iloc[i]),\n",
    "                                              corrector.dictionary_relaxed)\n",
    "\n",
    "        data_piece[\"We\"] = [We[i]] * len(candidates)\n",
    "        data_piece[\"Wc\"] = candidates.keys()\n",
    "        data_piece[\"x1\"] = dist_score.values()\n",
    "        data_piece[\"x2\"] = simi_score.values()\n",
    "        data_piece[\"x3\"] = popu_score.values()\n",
    "        data_piece[\"x4\"] = exis_score.values()\n",
    "        data_piece[\"x5\"] = exat_score.values()\n",
    "        data_piece[\"x6\"] = rela_score.values()\n",
    "\n",
    "        label_list = []\n",
    "        for j in range(len(candidates)):\n",
    "            if data_piece.iloc[j, 1] == Truth[i]:\n",
    "                label_list.append(1)\n",
    "            else:\n",
    "                label_list.append(0)\n",
    "        data_piece[\"label\"] = label_list\n",
    "        dataset = dataset.append(data_piece, ignore_index=True)\n",
    "    \n",
    "    dataset.to_pickle(os.path.join(Correction_wd, \"dataset.pkl\"))\n",
    "    toc = time.clock()\n",
    "    print(toc-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "We = list(set(dataset.We))\n",
    "We_train, We_test = train_test_split(We, test_size = 0.25)\n",
    "train_index = [We in We_train for We in dataset.We]\n",
    "train_data = dataset[train_index]\n",
    "test_index = [not boolean for boolean in train_index]\n",
    "test_data = dataset[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_data.iloc[:,2:8]\n",
    "train_y = train_data.label\n",
    "test_X = test_data.iloc[:,2:8]\n",
    "test_y = test_data.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "         n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = AdaBoostRegressor()\n",
    "regressor.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicttion_raw = regressor.predict(test_X).tolist()\n",
    "test_data['prediction'] = predicttion_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = test_data.groupby('We', as_index=False).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871977240398293"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(result.label)/len(result.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>We</th>\n",
       "      <th>Wc</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accommsamms</td>\n",
       "      <td>recommends</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.224056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            We          Wc        x1   x2   x3  x4   x5   x6  label  \\\n",
       "1  accommsamms  recommends  0.285714  0.5  1.0   1  0.0  1.0      0   \n",
       "\n",
       "   prediction  \n",
       "1    0.224056  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('testResults.csv', index=False, sep=',')\n",
    "result.to_csv('correctionResult.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
